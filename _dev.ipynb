{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import torch\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "#from torchmetrics import JaccardIndex\n",
    "import seaborn as sbn\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, r2_score\n",
    "import time\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import copy \n",
    "from scipy.stats import spearmanr\n",
    "import h5py\n",
    "\n",
    "import sys \n",
    "sys.path.append('./src/')\n",
    "from data_loading import load_tabular_data, preprocess_data, corrupt_label\n",
    "from DVGS import DVGS\n",
    "from DVRL import DVRL\n",
    "from utils import get_corruption_scores\n",
    "from NN import NN\n",
    "from AE import AE\n",
    "import similarities \n",
    "import DShap\n",
    "from LOO import LOO\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from utils import load_data, get_filtered_scores\n",
    "from LincsEmbNN import LincsEmbNN\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression# CV\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>pert_idx</th>\n",
       "      <th>cell_idx</th>\n",
       "      <th>log_conc</th>\n",
       "      <th>z_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABY001_A375_XH:BRD-A61304759:0.625:24</td>\n",
       "      <td>1425</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.20412</td>\n",
       "      <td>0.472838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABY001_A375_XH:BRD-A61304759:0.625:3</td>\n",
       "      <td>1425</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.20412</td>\n",
       "      <td>-2.140817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABY001_A375_XH:BRD-A61304759:10:24</td>\n",
       "      <td>1425</td>\n",
       "      <td>4</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.472838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABY001_A375_XH:BRD-A61304759:10:3</td>\n",
       "      <td>1425</td>\n",
       "      <td>4</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-2.140817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABY001_A375_XH:BRD-A61304759:2.5:24</td>\n",
       "      <td>1425</td>\n",
       "      <td>4</td>\n",
       "      <td>0.39794</td>\n",
       "      <td>0.472838</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  sig_id  pert_idx  cell_idx  log_conc  \\\n",
       "0  ABY001_A375_XH:BRD-A61304759:0.625:24      1425         4  -0.20412   \n",
       "1   ABY001_A375_XH:BRD-A61304759:0.625:3      1425         4  -0.20412   \n",
       "2     ABY001_A375_XH:BRD-A61304759:10:24      1425         4   1.00000   \n",
       "3      ABY001_A375_XH:BRD-A61304759:10:3      1425         4   1.00000   \n",
       "4    ABY001_A375_XH:BRD-A61304759:2.5:24      1425         4   0.39794   \n",
       "\n",
       "     z_time  \n",
       "0  0.472838  \n",
       "1 -2.140817  \n",
       "2  0.472838  \n",
       "3 -2.140817  \n",
       "4  0.472838  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "osig_idx = pd.read_csv('./data/processed/osig_indexed.tsv', sep='\\t')\n",
    "osig_idx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([     0,      1,      2, ..., 509984, 509985, 509986])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_idxs = (~osig_idx.pert_idx.isna()).values.nonzero()[0]\n",
    "_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([509987, 978])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = h5py.File('./data/processed/lincs.h5')\n",
    "y = torch.tensor(f['data'][_idxs, ...], dtype=torch.float32)\n",
    "y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "pert_idx = torch.tensor(osig_idx.pert_idx.values[_idxs], dtype=torch.long)\n",
    "cell_idx = torch.tensor(osig_idx.cell_idx.values[_idxs], dtype=torch.long)\n",
    "log_conc = torch.tensor(osig_idx.log_conc.values[_idxs], dtype=torch.float32)\n",
    "z_time = torch.tensor(osig_idx.z_time.values[_idxs], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LincsEmbNN(cell_channels    = 64, \n",
    "                   num_lines        = osig_idx.cell_idx.max() + 1, \n",
    "                   pert_channels    = 64, \n",
    "                   num_perts        = osig_idx.pert_idx.max() + 1, \n",
    "                   out_channels     = 978, \n",
    "                   num_layers       = 2, \n",
    "                   hidden_channels  = 400, \n",
    "                   norm             = True, \n",
    "                   dropout          = 0.05, \n",
    "                   act              = torch.nn.Mish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 || avg. loss: 0.9021 || avg. R2: -0.0104\n",
      "epoch: 1 || avg. loss: 0.8926 || avg. R2: 0.0001\n",
      "epoch: 2 || avg. loss: 0.8881 || avg. R2: 0.0053\n",
      "epoch: 3 || avg. loss: 0.8824 || avg. R2: 0.0121\n",
      "epoch: 4 || avg. loss: 0.8777 || avg. R2: 0.0182\n",
      "epoch: 5 || avg. loss: 0.8728 || avg. R2: 0.0229\n",
      "epoch: 6 || avg. loss: 0.8679 || avg. R2: 0.0279\n",
      "epoch: 7 || avg. loss: 0.8641 || avg. R2: 0.0325\n",
      "epoch: 8 || avg. loss: 0.8602 || avg. R2: 0.0358\n",
      "epoch: 9 || avg. loss: 0.8566 || avg. R2: 0.0400\n",
      "epoch: 10 || avg. loss: 0.8545 || avg. R2: 0.0423\n",
      "epoch: 11 || avg. loss: 0.8508 || avg. R2: 0.0460\n",
      "epoch: 12 || avg. loss: 0.8486 || avg. R2: 0.0492\n",
      "epoch: 13 || avg. loss: 0.8461 || avg. R2: 0.0520\n",
      "epoch: 14 || avg. loss: 0.8438 || avg. R2: 0.0547\n",
      "epoch: 15 || avg. loss: 0.8409 || avg. R2: 0.0574\n",
      "epoch: 16 || avg. loss: 0.8390 || avg. R2: 0.0596\n",
      "epoch: 17 || avg. loss: 0.8369 || avg. R2: 0.0618\n",
      "epoch: 18 || avg. loss: 0.8356 || avg. R2: 0.0643\n",
      "epoch: 19 || avg. loss: 0.8339 || avg. R2: 0.0661\n",
      "epoch: 20 || avg. loss: 0.8324 || avg. R2: 0.0667\n",
      "epoch: 21 || avg. loss: 0.8309 || avg. R2: 0.0694\n",
      "epoch: 22 || avg. loss: 0.8292 || avg. R2: 0.0708\n",
      "epoch: 23 || avg. loss: 0.8266 || avg. R2: 0.0731\n",
      "epoch: 24 || avg. loss: 0.8251 || avg. R2: 0.0748\n",
      "epoch: 25 || avg. loss: 0.8256 || avg. R2: 0.0750\n",
      "epoch: 26 || avg. loss: 0.8246 || avg. R2: 0.0762\n",
      "epoch: 27 || avg. loss: 0.8233 || avg. R2: 0.0772\n",
      "epoch: 28 || avg. loss: 0.8224 || avg. R2: 0.0779\n",
      "epoch: 29 || avg. loss: 0.8220 || avg. R2: 0.0788\n",
      "epoch: 30 || avg. loss: 0.8196 || avg. R2: 0.0811\n",
      "epoch: 31 || avg. loss: 0.8192 || avg. R2: 0.0821\n",
      "epoch: 32 || avg. loss: 0.8182 || avg. R2: 0.0833\n",
      "epoch: 33 || avg. loss: 0.8168 || avg. R2: 0.0843\n",
      "epoch: 34 || avg. loss: 0.8159 || avg. R2: 0.0857\n",
      "epoch: 35 || avg. loss: 0.8153 || avg. R2: 0.0859\n",
      "epoch: 36 || avg. loss: 0.8153 || avg. R2: 0.0870\n",
      "epoch: 37 || avg. loss: 0.8129 || avg. R2: 0.0881\n",
      "epoch: 38 || avg. loss: 0.8130 || avg. R2: 0.0882\n",
      "epoch: 39 || avg. loss: 0.8136 || avg. R2: 0.0880\n",
      "epoch: 40 || avg. loss: 0.8136 || avg. R2: 0.0881\n",
      "epoch: 41 || avg. loss: 0.8131 || avg. R2: 0.0889\n",
      "epoch: 42 || avg. loss: 0.8118 || avg. R2: 0.0900\n",
      "epoch: 43 || avg. loss: 0.8101 || avg. R2: 0.0916\n",
      "epoch: 44 || avg. loss: 0.8110 || avg. R2: 0.0911\n",
      "epoch: 45 || avg. loss: 0.8096 || avg. R2: 0.0925\n",
      "epoch: 46 || avg. loss: 0.8082 || avg. R2: 0.0937\n",
      "epoch: 47 || avg. loss: 0.8078 || avg. R2: 0.0945\n",
      "epoch: 48 || avg. loss: 0.8079 || avg. R2: 0.0949\n",
      "epoch: 49 || avg. loss: 0.8090 || avg. R2: 0.0934\n",
      "epoch: 50 || avg. loss: 0.8077 || avg. R2: 0.0946\n",
      "epoch: 51 || avg. loss: 0.8055 || avg. R2: 0.0965\n",
      "epoch: 52 || avg. loss: 0.8063 || avg. R2: 0.0970\n",
      "epoch: 53 || avg. loss: 0.8061 || avg. R2: 0.0971\n",
      "epoch: 54 || avg. loss: 0.8049 || avg. R2: 0.0977\n",
      "epoch: 55 || avg. loss: 0.8043 || avg. R2: 0.0983\n",
      "epoch: 56 || avg. loss: 0.8042 || avg. R2: 0.0984\n",
      "epoch: 57 || avg. loss: 0.8034 || avg. R2: 0.0994\n",
      "epoch: 58 || avg. loss: 0.8018 || avg. R2: 0.1005\n",
      "epoch: 59 || avg. loss: 0.8027 || avg. R2: 0.1004\n",
      "epoch: 60 || avg. loss: 0.8031 || avg. R2: 0.0993\n",
      "epoch: 61 || avg. loss: 0.8029 || avg. R2: 0.1003\n",
      "epoch: 62 || avg. loss: 0.8022 || avg. R2: 0.1014\n",
      "epoch: 63 || avg. loss: 0.8013 || avg. R2: 0.1018\n",
      "epoch: 64 || avg. loss: 0.8006 || avg. R2: 0.1025\n",
      "epoch: 65 || avg. loss: 0.8009 || avg. R2: 0.1024\n",
      "epoch: 66 || avg. loss: 0.8015 || avg. R2: 0.1013\n",
      "epoch: 67 || avg. loss: 0.8000 || avg. R2: 0.1025\n",
      "epoch: 68 || avg. loss: 0.8012 || avg. R2: 0.1031\n",
      "epoch: 69 || avg. loss: 0.7996 || avg. R2: 0.1037\n",
      "epoch: 70 || avg. loss: 0.7983 || avg. R2: 0.1048\n",
      "epoch: 71 || avg. loss: 0.7982 || avg. R2: 0.1052\n",
      "epoch: 72 || avg. loss: 0.7972 || avg. R2: 0.1058\n",
      "epoch: 73 || avg. loss: 0.7985 || avg. R2: 0.1050\n",
      "epoch: 74 || avg. loss: 0.7965 || avg. R2: 0.1069\n",
      "epoch: 75 || avg. loss: 0.7964 || avg. R2: 0.1076\n",
      "epoch: 76 || avg. loss: 0.7972 || avg. R2: 0.1065\n",
      "epoch: 77 || avg. loss: 0.7972 || avg. R2: 0.1057\n",
      "epoch: 78 || avg. loss: 0.7968 || avg. R2: 0.1077\n",
      "epoch: 79 || avg. loss: 0.7967 || avg. R2: 0.1070\n",
      "epoch: 80 || avg. loss: 0.7971 || avg. R2: 0.1067\n",
      "epoch: 81 || avg. loss: 0.7951 || avg. R2: 0.1090\n",
      "epoch: 82 || avg. loss: 0.7940 || avg. R2: 0.1101\n",
      "epoch: 83 || avg. loss: 0.7959 || avg. R2: 0.1085\n",
      "epoch: 84 || avg. loss: 0.7948 || avg. R2: 0.1095\n",
      "epoch: 85 || avg. loss: 0.7947 || avg. R2: 0.1089\n",
      "epoch: 86 || avg. loss: 0.7929 || avg. R2: 0.1108\n",
      "epoch: 87 || avg. loss: 0.7936 || avg. R2: 0.1104\n",
      "epoch: 88 || avg. loss: 0.7929 || avg. R2: 0.1120\n",
      "epoch: 89 || avg. loss: 0.7924 || avg. R2: 0.1115\n",
      "epoch: 90 || avg. loss: 0.7937 || avg. R2: 0.1104\n",
      "epoch: 91 || avg. loss: 0.7924 || avg. R2: 0.1114\n",
      "epoch: 92 || avg. loss: 0.7919 || avg. R2: 0.1124\n",
      "epoch: 93 || avg. loss: 0.7923 || avg. R2: 0.1121\n",
      "epoch: 94 || avg. loss: 0.7919 || avg. R2: 0.1122\n",
      "epoch: 95 || avg. loss: 0.7911 || avg. R2: 0.1130\n",
      "epoch: 96 || avg. loss: 0.7908 || avg. R2: 0.1132\n",
      "epoch: 97 || avg. loss: 0.7909 || avg. R2: 0.1132\n",
      "epoch: 98 || avg. loss: 0.7895 || avg. R2: 0.1145\n",
      "epoch: 99 || avg. loss: 0.7898 || avg. R2: 0.1143\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda'\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "batch_size  = 1024\n",
    "epochs      = 100\n",
    "lr          = 1e-2 \n",
    "\n",
    "optim = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "crit = torch.nn.MSELoss() \n",
    "\n",
    "\n",
    "for epoch in range(epochs): \n",
    "    _losses = []\n",
    "    ii=0\n",
    "    _r2s = []\n",
    "    for batch_idx in torch.split(torch.randperm(y.size(0)), batch_size): \n",
    "\n",
    "        pert_batch = pert_idx[batch_idx].to(device)\n",
    "        cell_batch = cell_idx[batch_idx].to(device)\n",
    "        time_batch = z_time[batch_idx].to(device)\n",
    "        conc_batch = log_conc[batch_idx].to(device)\n",
    "\n",
    "        y_batch = y[batch_idx, :].to(device)\n",
    "\n",
    "        yhat = model(pert_idx=pert_batch, cell_idx=cell_batch, z_time=time_batch, log_conc=conc_batch)\n",
    "\n",
    "        optim.zero_grad()\n",
    "        loss = crit(yhat, y_batch)\n",
    "        loss.backward() \n",
    "        optim.step()\n",
    "        \n",
    "        _losses.append(loss.item())\n",
    "        _r2s.append(r2_score(y_batch.detach().cpu().numpy(), yhat.detach().cpu().numpy(), multioutput='uniform_average'))\n",
    "        print(f'[epoch progress: {ii}/{1+int(y.size(0)/batch_size)}]', end='\\r')\n",
    "        ii+=1\n",
    "\n",
    "    print(f'epoch: {epoch} || avg. loss: {np.mean(_losses):.4f} || avg. R2: {np.mean(_r2s):.4f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pert_id</th>\n",
       "      <th>target</th>\n",
       "      <th>pert_idx</th>\n",
       "      <th>DRD2</th>\n",
       "      <th>NR3C1</th>\n",
       "      <th>HTR2A</th>\n",
       "      <th>KDR</th>\n",
       "      <th>PTGS2</th>\n",
       "      <th>PTGS1</th>\n",
       "      <th>HRH1</th>\n",
       "      <th>...</th>\n",
       "      <th>SSTR5</th>\n",
       "      <th>ADIPOR2</th>\n",
       "      <th>SLC6A12</th>\n",
       "      <th>MAPK9</th>\n",
       "      <th>SSTR1</th>\n",
       "      <th>SLC29A1</th>\n",
       "      <th>MKNK1</th>\n",
       "      <th>MGMT</th>\n",
       "      <th>SPHK1</th>\n",
       "      <th>SLC52A2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BRD-A00077618</td>\n",
       "      <td>['PRKG1']</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BRD-A00100033</td>\n",
       "      <td>[nan]</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BRD-A00147595</td>\n",
       "      <td>['PPARG', 'PPARG']</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BRD-A00150179</td>\n",
       "      <td>[nan]</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BRD-A00218260</td>\n",
       "      <td>[nan]</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 609 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         pert_id              target  pert_idx   DRD2  NR3C1  HTR2A    KDR  \\\n",
       "0  BRD-A00077618           ['PRKG1']         0  False  False  False  False   \n",
       "1  BRD-A00100033               [nan]         1  False  False  False  False   \n",
       "2  BRD-A00147595  ['PPARG', 'PPARG']         2  False  False  False  False   \n",
       "3  BRD-A00150179               [nan]         3  False  False  False  False   \n",
       "4  BRD-A00218260               [nan]         4  False  False  False  False   \n",
       "\n",
       "   PTGS2  PTGS1   HRH1  ...  SSTR5  ADIPOR2  SLC6A12  MAPK9  SSTR1  SLC29A1  \\\n",
       "0  False  False  False  ...  False    False    False  False  False    False   \n",
       "1  False  False  False  ...  False    False    False  False  False    False   \n",
       "2  False  False  False  ...  False    False    False  False  False    False   \n",
       "3  False  False  False  ...  False    False    False  False  False    False   \n",
       "4  False  False  False  ...  False    False    False  False  False    False   \n",
       "\n",
       "   MKNK1   MGMT  SPHK1  SLC52A2  \n",
       "0  False  False  False    False  \n",
       "1  False  False  False    False  \n",
       "2  False  False  False    False  \n",
       "3  False  False  False    False  \n",
       "4  False  False  False    False  \n",
       "\n",
       "[5 rows x 609 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pert2targ = pd.read_csv('./data/processed/pert2targets.tsv', sep='\\t')\n",
    "pert2targ.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "606"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targspace = pert2targ.columns[3:]\n",
    "len(targspace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DRD2'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targspace[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "progress: 605/606\r"
     ]
    }
   ],
   "source": [
    "def get_pert_idx_pairs_with_shared_targets(pert2targ): \n",
    "\n",
    "    pos_class_idx1 = []\n",
    "    pos_class_idx2 = []\n",
    "\n",
    "    targspace = pert2targ.columns[3:]\n",
    "\n",
    "    for i,t in enumerate(targspace): \n",
    "        print(f'progress: {i}/{len(targspace)}', end='\\r')\n",
    "        perts_sharing_targ = pert2targ[t].values.nonzero()[0]\n",
    "        for j,p1 in enumerate(perts_sharing_targ): \n",
    "            for p2 in perts_sharing_targ[(j+1):]: \n",
    "                pos_class_idx1.append(p1)\n",
    "                pos_class_idx2.append(p2)\n",
    "\n",
    "    pos_class_idx1 = torch.tensor(pos_class_idx1, dtype=torch.long)\n",
    "    pos_class_idx2 = torch.tensor(pos_class_idx2, dtype=torch.long)\n",
    "\n",
    "    return pos_class_idx1, pos_class_idx2\n",
    "\n",
    "pos_class_idx1, pos_class_idx2 = get_pert_idx_pairs_with_shared_targets(pert2targ)\n",
    "\n",
    "neg_class_idx1 = torch.randint(osig_idx.pert_idx.max() + 1, size=(1000000,))  # grand majority of combinations are negative class ; random pairings should estimate neg\n",
    "neg_class_idx2 = torch.randint(osig_idx.pert_idx.max() + 1, size=(1000000,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0118)\n",
      "tensor(0.0007)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def batched_cosine_similarity(embedding, idx1, idx2, batch_size=1024, normalize=True): \n",
    "    ''''''\n",
    "\n",
    "    if normalize: \n",
    "        embedding = copy.deepcopy(embedding)\n",
    "        embedding.weight.data = embedding.weight.data - embedding.weight.data.mean(dim=0)\n",
    "        embedding.weight.data = embedding.weight.data / embedding.weight.data.std(dim=0)\n",
    "\n",
    "    cos_sim = torch.nn.CosineSimilarity(dim=1)\n",
    "    s = []\n",
    "    for batch_idx in torch.split(torch.arange(len(idx1)), batch_size):\n",
    "        with torch.no_grad(): \n",
    "            z1 = embedding(idx1[batch_idx])\n",
    "            z2 = embedding(idx2[batch_idx])\n",
    "            s.append( cos_sim(z1, z2) )\n",
    "\n",
    "    return torch.cat(s, dim=-1).mean()\n",
    "\n",
    "pos_sim = batched_cosine_similarity(model.pert_embedding.cpu(), pos_class_idx1, pos_class_idx2)\n",
    "neg_sim = batched_cosine_similarity(model.pert_embedding.cpu(), neg_class_idx1, neg_class_idx2)\n",
    "\n",
    "print(pos_sim)\n",
    "print(neg_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3.5895, -0.3356,  0.4950,  ..., -1.9853, -1.8826, -0.3900],\n",
       "        [-0.2993, -1.4494,  6.4771,  ...,  4.3259,  3.4183, -3.4906],\n",
       "        [ 3.9816,  0.4846,  0.8419,  ...,  6.7406,  4.3670, -5.4558],\n",
       "        ...,\n",
       "        [-4.4173,  1.0471, -0.6121,  ...,  3.1440,  3.1208,  3.6972],\n",
       "        [-0.3667,  2.0897,  4.7883,  ...,  1.3937,  2.4289,  1.3639],\n",
       "        [-4.7490, -1.3679, -1.9048,  ..., -1.7002, -1.8848,  0.3995]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.pert_embedding.weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape (30519, 64)\n",
      "[49] targ: JAK2 \t|| roc: 0.7517 \t|| null model roc ci: 0.3743, 0.5592882\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>auroc</th>\n",
       "      <th>null_auroc_95ci</th>\n",
       "      <th>null_auroc_05ci</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DRD2</td>\n",
       "      <td>0.587785</td>\n",
       "      <td>0.557270</td>\n",
       "      <td>0.418583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NR3C1</td>\n",
       "      <td>0.611947</td>\n",
       "      <td>0.566616</td>\n",
       "      <td>0.433207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HTR2A</td>\n",
       "      <td>0.610038</td>\n",
       "      <td>0.548260</td>\n",
       "      <td>0.444339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KDR</td>\n",
       "      <td>0.585589</td>\n",
       "      <td>0.580446</td>\n",
       "      <td>0.452139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PTGS2</td>\n",
       "      <td>0.711895</td>\n",
       "      <td>0.563742</td>\n",
       "      <td>0.405501</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  target     auroc  null_auroc_95ci  null_auroc_05ci\n",
       "0   DRD2  0.587785         0.557270         0.418583\n",
       "1  NR3C1  0.611947         0.566616         0.433207\n",
       "2  HTR2A  0.610038         0.548260         0.444339\n",
       "3    KDR  0.585589         0.580446         0.452139\n",
       "4  PTGS2  0.711895         0.563742         0.405501"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cpu()\n",
    "\n",
    "x = model.pert_embedding(torch.tensor(pert2targ.pert_idx.values.astype(int), dtype=torch.long)).detach().cpu().numpy()\n",
    "\n",
    "#scaler = StandardScaler()\n",
    "#scaler.fit(x)\n",
    "#x = scaler.transform(x)\n",
    "\n",
    "print('x shape', x.shape)\n",
    "out = {'target': [], 'auroc':[], 'null_auroc_95ci':[], 'null_auroc_05ci':[]}\n",
    "\n",
    "for i,targ in enumerate(pert2targ.columns[3:]): \n",
    "    \n",
    "    y = pert2targ[targ].values*1.\n",
    "\n",
    "    #print('y shape', y.shape)\n",
    "    #print('y pos class:', y.mean())\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "    dti_model = LogisticRegression(class_weight='balanced', max_iter=1000)#, penalty='l2', solver='newton-cholesky') \n",
    "    #dti_model = SVC(kernel='linear', class_weight='balanced', max_iter=1000) \n",
    "    scores = cross_val_score(dti_model, x, y, scoring='roc_auc', cv=cv, n_jobs=5)\n",
    "\n",
    "    # This really doesn't need to be done every time\n",
    "    # since our performance is relative, doesn't necessarily need to be done at all\n",
    "    # nice as a check thought...\n",
    "    rand_scores = []\n",
    "    for j in range(10): \n",
    "        y_rand = np.random.permutation(y)\n",
    "        rand_scores.append(cross_val_score(dti_model, x, y_rand, scoring='roc_auc', cv=cv, n_jobs=5).mean())\n",
    "    rand_scores = np.array(rand_scores)\n",
    "\n",
    "    out['target'].append(targ)\n",
    "    out['auroc'].append(scores.mean())\n",
    "    out['null_auroc_05ci'].append(np.quantile(rand_scores, q=0.05))\n",
    "    out['null_auroc_95ci'].append(np.quantile(rand_scores, q=0.95))\n",
    "\n",
    "    print(f'[{i}] targ: {targ} \\t|| roc: {scores.mean():.4f} \\t|| null model roc ci: {np.quantile(rand_scores, q=0.05):.4f}, {np.quantile(rand_scores, q=0.95):.4f}', end='\\r')\n",
    "\n",
    "print()\n",
    "\n",
    "out = pd.DataFrame(out)\n",
    "out.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>auroc</th>\n",
       "      <th>null_auroc_95ci</th>\n",
       "      <th>q</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.595156</td>\n",
       "      <td>0.583986</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      auroc  null_auroc_95ci  q\n",
       "0  0.595156         0.583986  0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = out[['auroc', 'null_auroc_95ci']].mean().to_frame().T\n",
    "res = res.assign(q=0)\n",
    "res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dvgs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7a0c01d8e4fa1db1da0660ba3ef0ec4ab134f84670460ef20ad46a30fcd2cd9f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
